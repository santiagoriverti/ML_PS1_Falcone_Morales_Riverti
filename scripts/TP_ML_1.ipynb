{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Librerías a utilizar\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Base URL sin número de página\n",
    "base_url = 'https://ignaciomsarmiento.github.io/GEIH2018_sample/pages/geih_page_{}.html'\n",
    "\n",
    "# Lista para almacenar los datos de todas las páginas\n",
    "all_data = []\n",
    "\n",
    "# Loop para iterar por las páginas 1 a 10\n",
    "for page in range(1, 11):\n",
    "    # Construir la URL para cada página\n",
    "    url = base_url.format(page)\n",
    "    \n",
    "    # Enviar una solicitud HTTP\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Verificar si la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Parsear el contenido con BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        \n",
    "        # Extraer encabezados solo en la primera iteración (ya se verifico que todas las paginas tienen el mismo encabezado)\n",
    "        if page == 1:\n",
    "            headers = [header.text.strip() for header in table.find_all('th')]\n",
    "        \n",
    "        # Extraer las filas de la tabla\n",
    "        for row in table.find_all('tr'):\n",
    "            row_data = [cell.text.strip() for cell in row.find_all('td')]\n",
    "            if row_data:\n",
    "                all_data.append(row_data)\n",
    "    else:\n",
    "        print(f\"No se pudo acceder a la página {page}\")\n",
    "\n",
    "# Crear un DataFrame con los datos recopilados\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#ETIQUETAS DE VARIABLES \n",
    "# Ruta del archivo PDF local\n",
    "pdf_path = r\"ddi-documentation-spanish-608.pdf\"\n",
    "\n",
    "# Función para extraer tablas de las páginas 23 a 56 y convertirlas en un solo DataFrame o lista de DataFrames\n",
    "def extract_tables_to_dataframe(pdf_path, start_page, end_page, combine=False):\n",
    "    all_tables = []\n",
    "    \n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i in range(start_page - 1, end_page):  # start_page=23, end_page=56\n",
    "            page = pdf.pages[i]\n",
    "            # Extraer las tablas de la página\n",
    "            tables = page.extract_tables()\n",
    "            \n",
    "            # Convertir cada tabla a un DataFrame y agregarla a la lista\n",
    "            for table in tables:\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])  # La primera fila es usada como cabecera\n",
    "                all_tables.append(df)\n",
    "    \n",
    "    # Retorna un solo DataFrame concatenado si combine=True\n",
    "    if combine:\n",
    "        combined_df = pd.concat(all_tables, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        return all_tables\n",
    "\n",
    "# Extraer y combinar las tablas en un solo DataFrame de las páginas 23 a 56\n",
    "combined_dataframe = extract_tables_to_dataframe(pdf_path, 23, 56, combine=True)\n",
    "combined_dataframe.columns = list(range(1, len(combined_dataframe.columns) + 1))\n",
    "\n",
    "combined_dataframe = combined_dataframe.drop([1, 2, 9], axis=1)\n",
    "combined_dataframe = combined_dataframe.drop(index=list(range(0, 6)) + list(range(31, 37)))\n",
    "combined_dataframe.columns = [\"ID\", \"nombre\", \"Etiqueta\", \"Tipo\", \"Formato\", \"Pregunta\"]\n",
    "combined_dataframe.to_excel('descripcion variables.xlsx', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pyodide)",
   "language": "python",
   "name": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
